What the graphs folder is
A single source of truth for all dataset CSVs used by both HEFT and PEFT.
Each runnable scenario needs three core inputs:
DAG (task graph): <prefix>_task_connectivity.csv
Processor interconnect: <prefix>_resource_BW.csv
Task runtimes per processor: <prefix>_task_exe_time.csv
Optional EDP/energy input:
<prefix>_task_power.csv
Some bandwidth files may include startup costs in the last row (e.g., canonicalgraph_resource_BW_startup.csv). HEFT detects this and splits the startup vector automatically.
What each file set represents
canonicalgraph_*: Classic HEFT example (Topcuoglu 2002).
peftgraph_*: Classic PEFT example (Arabnejad 2014).
randomgraph_*: A sample random DAG dataset.
globalgraph_*, mygraph_*, mygraph_peft_*: Datasets generated by the graph generator (you created these).
Only the files ending with _task_connectivity.csv are actual task DAGs. The “other” files in each set are the supporting matrices required to schedule that DAG:

_resource_BW.csv: q×q bandwidth matrix between processors (optionally with a final “Startup” row in the startup variant).
_task_exe_time.csv: v×q matrix of execution times per (task, processor).
_task_power.csv: Optional per-(task, processor) power for EDP modes.
Which files to use together (examples)
HEFT with canonical:
-d canonicalgraph_task_connectivity.csv
-p canonicalgraph_resource_BW.csv
-t canonicalgraph_task_exe_time.csv
HEFT with startup:
-p canonicalgraph_resource_BW_startup.csv (auto-splits startup row)
PEFT with peftgraph:
-d peftgraph_task_connectivity.csv
-p peftgraph_resource_BW.csv
-t peftgraph_task_exe_time.csv
Generated graph (e.g., globalgraph_…):
-d globalgraph_task_connectivity.csv
-p globalgraph_resource_BW.csv
-t globalgraph_task_exe_time.csv
If you add a new DAG, ensure its matching resource_BW and task_exe_time files exist; otherwise the schedulers won’t have the complete inputs they need.